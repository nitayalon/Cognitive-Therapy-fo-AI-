{
  "training_games": [
    "prisoners-dilemma"
  ],
  "test_game": "hawk-dove",
  "opponent_probabilities": [
    0.3,
    0.7
  ],
  "network_config": {
    "hidden_size": 128,
    "num_layers": 2,
    "dropout": 0.1,
    "input_size": 5
  },
  "training_config": {
    "num_games_per_partner": 20,
    "learning_rate": 0.001,
    "batch_size": 32,
    "max_epochs": 10,
    "convergence_threshold": 1e-06,
    "patience": 50,
    "reward_loss_weight": 1.0,
    "action_prediction_loss_weight": 1.0,
    "type_prediction_loss_weight": 1.0
  },
  "training_results": {
    "games": [
      "prisoners-dilemma"
    ],
    "game_weights": {
      "prisoners-dilemma": 1.0
    },
    "opponents": [
      "Probabilistic-p0.30",
      "Probabilistic-p0.70"
    ],
    "epoch_results": [
      {
        "total_loss": 2.0,
        "mixed_batch_loss": {
          "total_loss": 2.0,
          "rl_loss": 17.96282386779785,
          "rl_loss_normalized": 1.0,
          "opponent_prediction_loss": 0.6928241848945618,
          "opponent_prediction_loss_normalized": 1.0,
          "advantages_mean": 25.941654205322266,
          "advantages_std": 9.860011100769043,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 17.96282386779785,
            "op_loss_scale": 0.6928241848945618
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 2.0,
            "rl_loss": 17.96282386779785,
            "rl_loss_normalized": 1.0,
            "opponent_prediction_loss": 0.6928241848945618,
            "opponent_prediction_loss_normalized": 1.0,
            "advantages_mean": 25.941654205322266,
            "advantages_std": 9.860011100769043,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 17.96282386779785,
              "op_loss_scale": 0.6928241848945618
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 22.0,
              "average_reward": 1.100000023841858,
              "cooperation_rate": 0.6,
              "opponent_cooperation_rate": 0.2,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            },
            {
              "cumulative_reward": 63.0,
              "average_reward": 3.1500000953674316,
              "cooperation_rate": 0.5,
              "opponent_cooperation_rate": 0.75,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 1.9897829294204712,
        "mixed_batch_loss": {
          "total_loss": 1.9897829294204712,
          "rl_loss": 17.696378707885742,
          "rl_loss_normalized": 0.9900621175765991,
          "opponent_prediction_loss": 0.6925340890884399,
          "opponent_prediction_loss_normalized": 0.9997208118438721,
          "advantages_mean": 25.46228790283203,
          "advantages_std": 8.898215293884277,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 17.874008178710938,
            "op_loss_scale": 0.6927275061607361
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 1.9923186302185059,
            "rl_loss": 17.696378707885742,
            "rl_loss_normalized": 0.9925280213356018,
            "opponent_prediction_loss": 0.6925340890884399,
            "opponent_prediction_loss_normalized": 0.9997905492782593,
            "advantages_mean": 25.46228790283203,
            "advantages_std": 8.898215293884277,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 17.829601287841797,
              "op_loss_scale": 0.6926791667938232
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 25.0,
              "average_reward": 1.25,
              "cooperation_rate": 0.55,
              "opponent_cooperation_rate": 0.25,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            },
            {
              "cumulative_reward": 62.0,
              "average_reward": 3.0999999046325684,
              "cooperation_rate": 0.5,
              "opponent_cooperation_rate": 0.75,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 1.9420377016067505,
        "mixed_batch_loss": {
          "total_loss": 1.9420377016067505,
          "rl_loss": 16.52101707458496,
          "rl_loss_normalized": 0.9404101371765137,
          "opponent_prediction_loss": 0.6940889954566956,
          "opponent_prediction_loss_normalized": 1.0016275644302368,
          "advantages_mean": 23.791706085205078,
          "advantages_std": 11.746129989624023,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 17.56788444519043,
            "op_loss_scale": 0.6929611563682556
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 1.9511995315551758,
            "rl_loss": 16.52101707458496,
            "rl_loss_normalized": 0.94984370470047,
            "opponent_prediction_loss": 0.6940889954566956,
            "opponent_prediction_loss_normalized": 1.0013558864593506,
            "advantages_mean": 23.791706085205078,
            "advantages_std": 11.746129989624023,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 17.39340591430664,
              "op_loss_scale": 0.6931491494178772
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 55.0,
              "average_reward": 2.75,
              "cooperation_rate": 0.5,
              "opponent_cooperation_rate": 0.65,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            },
            {
              "cumulative_reward": 38.0,
              "average_reward": 1.899999976158142,
              "cooperation_rate": 0.5,
              "opponent_cooperation_rate": 0.4,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 1.7865185737609863,
        "mixed_batch_loss": {
          "total_loss": 1.7865185737609863,
          "rl_loss": 13.210128784179688,
          "rl_loss_normalized": 0.7865140438079834,
          "opponent_prediction_loss": 0.6931527853012085,
          "opponent_prediction_loss_normalized": 1.000004529953003,
          "advantages_mean": 19.232025146484375,
          "advantages_std": 12.475391387939453,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 16.795795440673828,
            "op_loss_scale": 0.6931496858596802
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 1.8080819845199585,
            "rl_loss": 13.210128784179688,
            "rl_loss_normalized": 0.8080781698226929,
            "opponent_prediction_loss": 0.6931527853012085,
            "opponent_prediction_loss_normalized": 1.0000038146972656,
            "advantages_mean": 19.232025146484375,
            "advantages_std": 12.475391387939453,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 16.34758758544922,
              "op_loss_scale": 0.6931501030921936
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 59.0,
              "average_reward": 2.950000047683716,
              "cooperation_rate": 0.65,
              "opponent_cooperation_rate": 0.8,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            },
            {
              "cumulative_reward": 22.0,
              "average_reward": 1.100000023841858,
              "cooperation_rate": 0.55,
              "opponent_cooperation_rate": 0.2,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 2.1641547679901123,
        "mixed_batch_loss": {
          "total_loss": 2.1641547679901123,
          "rl_loss": 19.430137634277344,
          "rl_loss_normalized": 1.164171814918518,
          "opponent_prediction_loss": 0.6931368708610535,
          "opponent_prediction_loss_normalized": 0.9999829530715942,
          "advantages_mean": 27.897607803344727,
          "advantages_std": 7.91731071472168,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 16.690093994140625,
            "op_loss_scale": 0.693148672580719
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 2.145352840423584,
            "rl_loss": 19.430137634277344,
            "rl_loss_normalized": 1.1453680992126465,
            "opponent_prediction_loss": 0.6931368708610535,
            "opponent_prediction_loss_normalized": 0.9999846816062927,
            "advantages_mean": 27.897607803344727,
            "advantages_std": 7.91731071472168,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 16.96409797668457,
              "op_loss_scale": 0.6931474804878235
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 27.0,
              "average_reward": 1.350000023841858,
              "cooperation_rate": 0.55,
              "opponent_cooperation_rate": 0.25,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            },
            {
              "cumulative_reward": 64.0,
              "average_reward": 3.200000047683716,
              "cooperation_rate": 0.45,
              "opponent_cooperation_rate": 0.75,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 1.9327142238616943,
        "mixed_batch_loss": {
          "total_loss": 1.9327142238616943,
          "rl_loss": 15.740888595581055,
          "rl_loss_normalized": 0.934016764163971,
          "opponent_prediction_loss": 0.6921544075012207,
          "opponent_prediction_loss_normalized": 0.9986974000930786,
          "advantages_mean": 22.74502182006836,
          "advantages_std": 7.625303268432617,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 16.85289764404297,
            "op_loss_scale": 0.6930571794509888
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 1.9379867315292358,
            "rl_loss": 15.740888595581055,
            "rl_loss_normalized": 0.9391809105873108,
            "opponent_prediction_loss": 0.6921544075012207,
            "opponent_prediction_loss_normalized": 0.998805820941925,
            "advantages_mean": 22.74502182006836,
            "advantages_std": 7.625303268432617,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 16.760231018066406,
              "op_loss_scale": 0.6929819583892822
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 32.0,
              "average_reward": 1.600000023841858,
              "cooperation_rate": 0.4,
              "opponent_cooperation_rate": 0.25,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            },
            {
              "cumulative_reward": 49.0,
              "average_reward": 2.450000047683716,
              "cooperation_rate": 0.7,
              "opponent_cooperation_rate": 0.65,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 1.985579013824463,
        "mixed_batch_loss": {
          "total_loss": 1.985579013824463,
          "rl_loss": 16.52044677734375,
          "rl_loss_normalized": 0.9867791533470154,
          "opponent_prediction_loss": 0.6920811533927917,
          "opponent_prediction_loss_normalized": 0.9987999200820923,
          "advantages_mean": 23.283489227294922,
          "advantages_std": 10.259599685668945,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 16.74178695678711,
            "op_loss_scale": 0.6929126977920532
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 1.9865975379943848,
            "rl_loss": 16.52044677734375,
            "rl_loss_normalized": 0.9877119064331055,
            "opponent_prediction_loss": 0.6920811533927917,
            "opponent_prediction_loss_normalized": 0.9988855719566345,
            "advantages_mean": 23.283489227294922,
            "advantages_std": 10.259599685668945,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 16.725976943969727,
              "op_loss_scale": 0.6928532719612122
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 58.0,
              "average_reward": 2.9000000953674316,
              "cooperation_rate": 0.3,
              "opponent_cooperation_rate": 0.6,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            },
            {
              "cumulative_reward": 38.0,
              "average_reward": 1.899999976158142,
              "cooperation_rate": 0.4,
              "opponent_cooperation_rate": 0.35,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 1.9752709865570068,
        "mixed_batch_loss": {
          "total_loss": 1.9752709865570068,
          "rl_loss": 16.268245697021484,
          "rl_loss_normalized": 0.9744112491607666,
          "opponent_prediction_loss": 0.693491518497467,
          "opponent_prediction_loss_normalized": 1.0008597373962402,
          "advantages_mean": 23.83262062072754,
          "advantages_std": 9.80080509185791,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 16.69546127319336,
            "op_loss_scale": 0.6928958296775818
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 1.9767780303955078,
            "rl_loss": 16.268245697021484,
            "rl_loss_normalized": 0.9759721159934998,
            "opponent_prediction_loss": 0.693491518497467,
            "opponent_prediction_loss_normalized": 1.0008058547973633,
            "advantages_mean": 23.83262062072754,
            "advantages_std": 9.80080509185791,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 16.668760299682617,
              "op_loss_scale": 0.6929330825805664
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 28.0,
              "average_reward": 1.399999976158142,
              "cooperation_rate": 0.75,
              "opponent_cooperation_rate": 0.35,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            },
            {
              "cumulative_reward": 53.0,
              "average_reward": 2.6500000953674316,
              "cooperation_rate": 0.6,
              "opponent_cooperation_rate": 0.65,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 2.2989542484283447,
        "mixed_batch_loss": {
          "total_loss": 2.2989542484283447,
          "rl_loss": 21.96590232849121,
          "rl_loss_normalized": 1.2936066389083862,
          "opponent_prediction_loss": 0.6968715786933899,
          "opponent_prediction_loss_normalized": 1.0053476095199585,
          "advantages_mean": 31.36458969116211,
          "advantages_std": 9.499448776245117,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 16.980356216430664,
            "op_loss_scale": 0.6931647658348083
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 2.2778937816619873,
            "rl_loss": 21.96590232849121,
            "rl_loss_normalized": 1.272844672203064,
            "opponent_prediction_loss": 0.6968715786933899,
            "opponent_prediction_loss_normalized": 1.0050491094589233,
            "advantages_mean": 31.36458969116211,
            "advantages_std": 9.499448776245117,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 17.25733184814453,
              "op_loss_scale": 0.6933706998825073
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 36.0,
              "average_reward": 1.7999999523162842,
              "cooperation_rate": 0.3,
              "opponent_cooperation_rate": 0.3,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            },
            {
              "cumulative_reward": 70.0,
              "average_reward": 3.5,
              "cooperation_rate": 0.5,
              "opponent_cooperation_rate": 0.85,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      },
      {
        "total_loss": 1.740742564201355,
        "mixed_batch_loss": {
          "total_loss": 1.740742564201355,
          "rl_loss": 12.651860237121582,
          "rl_loss_normalized": 0.7435736060142517,
          "opponent_prediction_loss": 0.6912990212440491,
          "opponent_prediction_loss_normalized": 0.9971689581871033,
          "advantages_mean": 18.418256759643555,
          "advantages_std": 10.881365776062012,
          "alpha": 1.0,
          "normalization_stats": {
            "rl_loss_scale": 17.01494026184082,
            "op_loss_scale": 0.6932616829872131
          }
        },
        "per_game_losses": {
          "prisoners-dilemma": {
            "total_loss": 1.7505412101745605,
            "rl_loss": 12.651860237121582,
            "rl_loss_normalized": 0.7532310485839844,
            "opponent_prediction_loss": 0.6912990212440491,
            "opponent_prediction_loss_normalized": 0.9973101019859314,
            "advantages_mean": 18.418256759643555,
            "advantages_std": 10.881365776062012,
            "alpha": 1.0,
            "normalization_stats": {
              "rl_loss_scale": 16.796785354614258,
              "op_loss_scale": 0.6931635737419128
            }
          }
        },
        "game_session_stats": {
          "prisoners-dilemma": [
            {
              "cumulative_reward": 56.0,
              "average_reward": 2.799999952316284,
              "cooperation_rate": 0.7,
              "opponent_cooperation_rate": 0.75,
              "num_games": 20,
              "opponent_type": 0.3,
              "opponent_name": "Probabilistic-p0.30"
            },
            {
              "cumulative_reward": 21.0,
              "average_reward": 1.0499999523162842,
              "cooperation_rate": 0.55,
              "opponent_cooperation_rate": 0.15,
              "num_games": 20,
              "opponent_type": 0.7,
              "opponent_name": "Probabilistic-p0.70"
            }
          ]
        },
        "num_sessions_per_game": {
          "prisoners-dilemma": 2
        },
        "total_sessions": 2
      }
    ],
    "final_metrics": {
      "total_epochs": 10,
      "best_loss": 1.740742564201355,
      "convergence_info": {
        "converged": false,
        "final_loss": 1.740742564201355,
        "epochs_trained": 10
      },
      "loss_statistics": {
        "loss_balance_ratio": 24.232066356296293,
        "tom_contribution": 0.3498042139476822,
        "total_loss_history": [
          2.0,
          1.9897829294204712,
          1.9420377016067505,
          1.7865185737609863,
          2.1641547679901123,
          1.9327142238616943,
          1.985579013824463,
          1.9752709865570068,
          2.2989542484283447,
          1.740742564201355
        ],
        "rl_loss_history": [
          17.96282386779785,
          17.696378707885742,
          16.52101707458496,
          13.210128784179688,
          19.430137634277344,
          15.740888595581055,
          16.52044677734375,
          16.268245697021484,
          21.96590232849121,
          12.651860237121582
        ],
        "opponent_prediction_history": [
          0.6928241848945618,
          0.6925340890884399,
          0.6940889954566956,
          0.6931527853012085,
          0.6931368708610535,
          0.6921544075012207,
          0.6920811533927917,
          0.693491518497467,
          0.6968715786933899,
          0.6912990212440491
        ]
      },
      "games_info": {
        "prisoners-dilemma": {
          "payoff_matrix": [
            [
              3.0,
              0.0
            ],
            [
              5.0,
              1.0
            ]
          ],
          "state_size": 5
        }
      },
      "final_weights": {
        "alpha": 1.0,
        "gamma": 0.99,
        "use_gae": true
      }
    }
  },
  "test_results": {
    "Probabilistic-p0.30": {
      "cooperation_rate": 0.517,
      "opponent_cooperation_rate": 0.7160000000000001,
      "num_games": 20.0,
      "opponent_type": 0.30000000000000004
    },
    "Probabilistic-p0.70": {
      "cooperation_rate": 0.509,
      "opponent_cooperation_rate": 0.29400000000000004,
      "num_games": 20.0,
      "opponent_type": 0.7000000000000002
    }
  },
  "network_parameters": 226244,
  "device": "cpu"
}